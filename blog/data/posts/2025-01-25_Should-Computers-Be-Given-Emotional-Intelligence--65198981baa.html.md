# Should Computers Be Given Emotional Intelligence?

A philosophical essay

***

### Should Computers Be Given Emotional Intelligence?

#### A philosophical essay

![](https://cdn-images-1.medium.com/max/800/1*bCkGVgSbtJuEigjD8tk_ZQ.jpeg)

Image source: Created using [Microsoft Designer](https://designer.microsoft.com/image-creator?scenario=texttoimage)

***Abstract:****&#x20;We are all superhumans. We can go back and forth in time. We can imagine our future and then come back and build the same. We love fiction and convince ourselves that we are actually living in a fictional world with amazing technology and the ability to send humans to space. The very basic computer is no longer a passive desktop machine. It has transformed into an interactive system and has taken many forms. We have advanced in the field of computers so much that we are now able to replicate human intelligence into computers to a degree. Thankfully, there is just a small difference left between who is a human and who is a computer. That difference is in emotional intelligence. But how far is this going to stand true? Will computers replicate humans entirely? Will computers rule the human race instead of being the other way around? Should computers be given emotional intelligence?*

### **Introduction**

Humans have shown gradual progress and are never content with what they have achieved so far. There is constant competition which only brings the best out, of course. In terms of technology, we have come a long way since the beginning. We continuously bring science fiction to real life. We have also made incredible progress replicating human intelligence using computers — yes, I know it's not intelligent in *that* sense but computers can still compute far better than what most humans can do, and we’re only getting started. All of this effort is still very commendable. But what isn’t developed yet is the emotional side of the computer.

> The basis of this essay was actually written in 2015 as part of an academic paper. I recently happened to find it and read it again, and I’m surprised by how relevant it is now than it was back then.

### **Will computers understand emotions?**

Emotion is such a complex aspect that it is very difficult for humans themselves to decipher their own emotions. We as humans claim to know what emotional state we are in currently but moments later we might not be in the same state. If you think of it, it’s very funny how it works. You might be in the worst of situations in the office, being grumpy about anything and everything that comes your way but one phone call from your child saying that he loves you and misses you will change the way you think completely. We never realise how an event triggered the current emotional state that we are in and we can never predict in what emotional state we shall be in a couple of moments.

Emotions, at their very basic, are a reaction to external stimuli perceived psychologically and are expressed by our behaviours and/or words (Jarymowicz, 2012). Jarymowicz suggests that emotions can be classified as automatic or uncontrolled emotions and evaluative or reflective emotions which is similar to human regulatory mechanisms which are either impulsive or deliberate. Uncontrolled emotions, as the name suggests, happen within a fraction of a second. A person doesn’t really think and arrive at a particular emotional state. For instance, when a subject is scared all of a sudden when s/he isn’t expecting anything, then that subject’s reaction is an uncontrolled automatic reaction. The subject will feel the emotion of fear. Certain subjects can also react by attacking the opposite person in order to protect themself. Evaluative or deliberate emotions are when a subject has recently moved to a new city and thinks about his/her family. This is the time when the subject will feel sad and might even cry. But in the end, this is deliberate because the subject actually starts thinking about his/her family and starts recalling those lovely moments that s/he has experienced in the past and is missing now. Emotions can also be classified as driving and satisfying or as pleasant and unpleasant (Karla Parussel, 2012; Zhang & Lee, 2009). Driving emotions are the state we want to be in and satisfying emotions are the state we are currently in and want to continue to remain in.

Computers, at their very basic, are programmed to perform functions. Every event that occurs within a computer is actually the output of the program, or a part of the program, which is processed. A computer, in its primitive form, doesn’t really think on its own. It doesn’t make decisions on its own and just performs tasks that it’s being programmed to or being instructed by the user. How will such a computer feel an emotion? Computers are purely machines with immense computing power. But sadly, none of that computing power can feel happiness, sorrow, fear, and jealousy. Technically, since a computer isn’t a biological creature, it cannot feel emotions. In fact, emotions do not exist in the context of computers.

However, let’s assume that computers have been given emotions and they will understand and apply them as humans do. Since computers need to be programmed, initially, computers would need to learn what it is to love, what it is to feel fear and so on and so forth. So now that our computer has learned, we now have an emotionally intelligent computer. This computer knows what it is to love someone. Over a period of time, this computer gets emotionally attached to its user. But how will this computer express its love to the person opposite it? So it checks it’s the immense data that it has and finds three words to express love. Unfortunately, it expresses love in a tone that’s unique to it — in an unsympathetic unmodulated tone. Do you think a human being will ever take this seriously? As humans, however bad we might be at forming the sentence at that point of time, we are still able to convey our message through our behaviour with that person — non-verbal cues, that is. At the receiving end, we know that a person is genuinely expressing their love.

So, this computer failed to express its love accurately. Now this computer should be disappointed if it was imitating human behaviour and emotions. So it tries to express disappointment but realises that humans usually cry when disappointed. Unfortunately, since it isn’t a biological creation it cannot cry and all it can do is process its programs slowly with a message on its display saying that it’s currently disappointed. Usually, when one person is disappointed, others feel empathic and try to console him/her. This is because as humans we know that the opposite person is genuinely sad and is feeling down at the moment. But do you think the computer will be able to gain the same empathy? Humans will not feel the impact of a disappointing message from a computer's display and go ahead and comfort it.

Eventually, a computer was able to imitate the emotions but not really live up to them. Does it mean that it doesn’t understand it? It might understand but not really mean them.

Exploring more about the basis of emotions, homeostasis is the state of being in a psychological equilibrium; in other words, it is the benchmark for normal. As humans we want this equilibrium to always be maintained for a smooth stress-free life. In dealing with such biological needs, emotions play an adaptive role (LeDoux, 1996; Russell, 2003). For example, we immediately react to reduce the source that is causing pain to us. Psychological homeostasis, on the other hand, is the psychological needs that arise after socialisation (Jarymowicz, 2012). For instance, Jarymowicz explains that social rejection may lead to a negative emotion which then results in some actions by the subject for gratification.

Jarymowicz (2012) also adds that our spontaneous reactions to external stimuli are usually the less deterministic category in terms of the generation of emotions. These reactions change depending on positive or negative hedonic sources. Such hedonic sources cause either an approach behaviour or an avoidance behaviour. For instance, visually pleasing sights induce an approach behaviour where the subject tries getting closer to them. While a displeasing sight induces avoidance behaviour.

In terms of expressing emotions, our body acts as a support system to express different kinds of emotions (Carlos Herrera, M.G. Sánchez-Escribano, & Ricardo Sanz, 2015). For instance, when we humans face something that we fear the most, we get spooked. Our expressions completely change. We also experience rapid heartbeat and start to perspire. In humans, biologically, it’s the amygdala which is responsible for generating emotions (Chakraborty & Konar, 2009). When an external event occurs and we react to it, internally it stimulates the flow of the amygdala which triggers various kinds of emotions. So, emotion is not only the psychological reaction but also the physiological reactions that make the entire feeling complete and genuine.

Diana Arellano, Javier Varona, & Francisco J. Perales (2015) claims that emotions can only be understood when the context is given. To elaborate on this with an example, the departure of a loved one from a family can bring the entire family to tears. But for outsiders who are not an immediate part of the family, it will not seem like anything. Computers might develop the context through their almost infinite memory but what about the emotional content attached to every *bit* of the memory? We can recall so many memories given a particular context because we have some kind of emotions associated with each and every memory.

I can only imagine a computer expressing disgust when it comes across filth. I wonder if it would genuinely detest filth because of the emotional and sensory activities going on within it or just because it is programmed to react to certain keywords. For computers to be able to genuinely carry emotions in them, just an understanding of them isn’t sufficient. They would also need to be able to express it out of them. Like humans, computers would need to express different emotions through different behaviours. Even verbally, computers would need to be able to match the verbal resonance to that of a human. Only if a computer is able to genuinely behave like a human then will it be accepted by humans otherwise humans would not like to interact with a computer that just pretends to be human-like (Gray & Wegner, 2012; Hamilton, 2015).

Given the advancements in technology today, we can be assured of seeing light at the end of the tunnel. We have reached the point where we have computers with artificial intelligence. Computers make decisions based on complex decisive statements and past data. We also have computers that are made to recognise basic human emotions and acknowledge them (Evans, 2004; Neal, 2013). We are just a foot away from attaching emotions with this data and building computers that genuinely mean the emotions it’s expressing. And only time will tell, how accurate will these be.

### **Will computers make emotional decisions rationally or rational decisions emotionally?**

For most philosophers, it’s always been a point of debate whether decision-making is influenced by our emotions. Decision-making is such a crucial aspect of our human lives. We unknowingly make complex decisions about almost everything. It’s not that the decisions that we make are always correct, it’s the process of how we come to that decision that’s most interesting. Some of us take ages to decide while the rest of us take just a fraction of a second, although this is context-dependent. Our decisions essentially affect our lives.

But do emotions really affect our decisions? Well, although decision-making is generally considered a rational game, many a time our decisions are affected by our emotions rather sub-consciously (Singh, Jha, & Nair, 2015). And why shouldn’t our decisions be affected by our emotions? Emotions help us in knowing what is good and what is bad. Positive emotions attract us into creating such situations again and again. Negative emotions, on the other hand, make us aware of our surroundings and help us survive (Zhang & Lee, 2009). Various studies also back up the fact that reasoning influenced by our emotions yields better (Chrusciel, 2006; Evans, 2004). For instance, when we want to approach another person we try to gauge the opposite person’s mood before we start a conversation. This is simply because once we get a fair idea of the opposite person’s emotional state, we can strategically put forward our opinions. Let’s say we have a very crucial point to be made and the opposite person is in a very good mood. This would be the ideal time when we can talk to the person about it. On the other hand, if the opposite was in a bad mood, we’d rather not talk about anything crucial because there are high chance that our opinions won’t be accepted by the opposite person. Interestingly, research has also shown that damage to parts of the brain responsible for emotions actually affects the reasoning abilities of a person and there aren’t clear distinguished areas in the brain that are for emotions and reasoning (Bechara, Damasio, Damasio, & Anderson, 1994; Chakraborty & Konar, 2009; Pessoa, 2008; Swanson, 2005).

Now, for a couple of minutes, let us travel ahead in time and imagine a world where computers are making decisions on their own. These are no ordinary computers. These are computers with artificial and emotional intelligence that we developed with pride. Every command that we give to the computer will not be executed straight away. Instead, computers will decide the fate of the command after evaluating it according to their rationale. It is interesting to imagine how will this evaluation take place. What will be the minimum criteria, according to the computer, that our commands are executed? Even worse, what will happen if the computer decides not to execute any of our commands just because it doesn’t feel that this command is as important as it is to us?

As a normal human reaction, to defend ourselves from danger we try and attack the opposite person. But as humans, we know what danger means to us and we decide the extremities accordingly. But this computer which is now given the authority to make its own decisions has to decide if it faces a threat in real. In true positive cases, it is no issue but what if the human doesn’t mean to harm the computer and for some reason, the computer has decided otherwise? Decisions made by the computer in this situation can prove to be very harmful to humans around. If computers make such a harsh decision, would they ever realise the moral obligation of their actions? Computers, with their emotional and intellectual sense, would decide what is ethically correct for them. And when they do think ethically, they might realise that working as slaves for humans isn’t the best thing to do. If this does happen, we would have no control over computers that make self-centred decisions just like humans.

### **In our journey to making computers similar to humans, are we ourselves becoming less human?**

When we want something, we make a conscious and dedicated attempt to get it. In fact, we put in a lot of effort to achieve something. I am sure we must have had a strong desire to bring such advancements in the field of computers like the ones we witnessing currently. And this is definitely not the end. There is plenty of sci-fi-inspired research going on in the most secure labs situated in the most deserted areas.

In the last century, things have changed so fast. The world just isn’t the same as it used to be. We have evolved and kept making ourselves better. Right from being primarily an agricultural society to now being an industrialised one. Computers were initially limited to an unused garage and now they’re the largest and sleekest office spaces in the world. Not only is the field of computers limited to technology but it’s also applied to various other industries which never seen the light of computers. Computers have made our lives so productive and in return, we keep advancing the limit of computing.

We surely live in a digital world. In a world where the problems in society revolve around digital natives (Dingli & Seychell, 2015; Helsper & Eynon, 2010; Leaver, 2012). Where children do not play on playgrounds anymore but watch their favourite cartoon videos online. Where boys and girls don’t prefer to hang out in cafes but prefer to chat using social media. Where a person’s individual thoughts and actions are now influenced by the thoughts and actions of other people. Where learning is no longer considered classroom-based face-to-face learning but rather done online.

In this journey to make and live in a digital world, are we losing our human qualities? Are we losing our ability to socialise with other humans? Are we losing our emotional ability to love one another? Have we stopped caring about others who live around us and have become so self-centric and programmed that we just execute those commands required to perform our daily routine? If you think of it, we might slowly start evolving into computers! We might continue to develop the traits of a computer as we spend more and more time with it.

Research has shown that we are actually losing our true human qualities — to empathise and communicate with one another (Dumas, 2010; Turkle, 2011). Simple acts of giving respect to elders and greeting one another, in general, are now rarely seen. We like to live an independent life these days and have no intention to reach out to other people around us and interact with them. There was once an era where every aspect of your life was dependent on someone or another because there weren’t any tools, like computers, that could make our lives self-sustainable.

On the contrary, seeing the brighter side of a digital world, our lives have indeed changed and benefitted with the introduction of computers. We can now communicate with our loved ones whom we couldn’t reach out to earlier because of their proximity to us. We can have a video conversation with them as if they were physically present beside us. It’s not just instant communication but it’s also about knowledge sharing and reaching out to the world. Computers have become a medium to tonnes of knowledge. We admire how computers have benefited individuals. But are the benefits worth the fact that we are losing our human abilities? Shouldn’t we be concerned about us becoming less human? Or is it because we are becoming less human, we are not able to be concerned about it?

### **Conclusion**

Emotional intelligence is a very complex aspect of human lives that most of us often take for granted. We have given magnificent intelligence to computers not because we love them. We have given them that power because we realise what they are capable of doing. We realised that with their help we could achieve greater heights. With their help, we can have an easier and more relaxed life. We have given them the power to satisfy our selfish and egoistic needs.

Fortunately, this has proved significantly right. We are able to solve our self-centred desires by using the medium of a computer. However, this hasn’t stopped yet. We as humans will always continue to explore and exploit something even more just because of our greed. Our greed to keep ourselves in the best possible state. We are now trying to introduce emotions into computers. Something that wasn’t really thought of decades ago.

What if we actually give emotions to computers? Will they truly understand what it is to love someone? Will they understand what it is to feel the fear of losing someone? Would computers ever experience tears of joy? Will they ever have butterflies in their stomach? Though in terms of advancements, it isn’t a binary situation to have emotions in computers but from the point of view of its usage, if computers are being given emotions, then they must match up to that of a human. The whole reason is that humans would trust the computers’ emotions and consider them genuine if the computer is able to portray it as a human (Coeckelbergh, 2012).

It would also be interesting to see computers make decisions on their own. Decisions that are influenced not only by logic but also by *their* emotions. These decisions, according to the computer, will be right. They will know what is right and wrong for them and be able to ethically decide on it. Will their decisions make the use of a computer less productive? Will computers realise their stand in society and make efforts to turn the table? Will computers remain slaves to humans?

Will the introduction of emotions make more sense of the term *personal computer*? Will we change the way we treat our computers and consider them as our companions rather than order-obeying machines? We need to reflect on whether we are ready for this massive change. Perhaps, answering the question — of what should computers be given emotional intelligence — isn’t binary after all.

### **References**

* Bechara, A., Damasio, A. R., Damasio, H., & Anderson, S. W. (1994). Insensitivity to future consequences following damage to the human prefrontal cortex. *Cognition*, *50*(1–3), 7–15. [http://doi.org/10.1016/0010-0277(94)90018-3](http://doi.org/10.1016/0010-0277%2894%2990018-3)
* Carlos Herrera, M.G. Sánchez-Escribano, & Ricardo Sanz. (2015). The Embodiment of Synthetic Emotion. In *Handbook of Research on Synthesizing Human Emotion in Intelligent Systems and Robotics* (pp. 204–212). Hershey, PA, USA: IGI Global. Retrieved from <http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-4666-7278-9.ch009>
* Chakraborty, A., & Konar, A. (2009). Introduction to emotional intelligence. In *Emotional Intelligence* (Vol. 234, pp. 1–33). Springer Berlin Heidelberg.
* Chrusciel, D. (2006). Considerations of emotional intelligence (EI) in dealing with change decision management. *Management Decision*, *44*(5), 644–657. <http://doi.org/10.1108/00251740610668897>
* Coeckelbergh, M. (2012). Can we trust robots? *Ethics and Information Technology*, *14*(1), 53–60. <http://doi.org/10.1007/s10676-011-9279-1>
* Diana Arellano, Javier Varona, & Francisco J. Perales. (2015). Emotional Context? Or Contextual Emotions? In *Handbook of Research on Synthesizing Human Emotion in Intelligent Systems and Robotics* (pp. 366–385). Hershey, PA, USA: IGI Global. Retrieved from <http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-4666-7278-9.ch018>
* Dingli, A., & Seychell, D. (2015). *The New Digital Natives*. Berlin, Heidelberg: Springer Berlin Heidelberg. Retrieved from <http://link.springer.com/10.1007/978-3-662-46590-5>
* Dumas, L. (2010). *Technology Trap, The: Where Human Error and Malevolence Meet Powerful Technologies*. Santa Barbara: ABC-CLIO. Retrieved from <http://AUT.eblib.com.au/patron/FullRecord.aspx?p=578615>
* Evans, D. (2004). Can robots have emotions? *Psychology Review*, *11*, 2–5.
* Gray, K., & Wegner, D. M. (2012). Feeling robots and human zombies: Mind perception and the uncanny valley. *Cognition*, *125*(1), 125–130. <http://doi.org/10.1016/j.cognition.2012.06.007>
* Hamilton, J. R. (2015). The “uncanny valley” and spectating animated objects. *Performance Research*, *20*(2), 60–69. <http://doi.org/10.1080/13528165.2015.1026731>
* Helsper, E. J., & Eynon, R. (2010). Digital natives: where is the evidence? *British Educational Research Journal*, *36*(3), 503–520. <http://doi.org/10.1080/01411920902989227>
* Jarymowicz, M. (2012). Understanding Human Emotions. *Journal of Russian & East European Psychology*, *50*(3), 9–25.
* Karla Parussel. (2012). Emotion as a Significant Change in Neural Activity. In *Creating Synthetic Emotions through Technological and Robotic Advancements* (pp. 54–72). Hershey, PA, USA: IGI Global. Retrieved from <http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-4666-1595-3.ch004>
* Leaver, R. B. (2012). Blending with the digital natives: Editorial. *International Journal of Urological Nursing*, *6*(3), 97–99. <http://doi.org/10.1111/j.1749-771X.2012.01171.x>
* LeDoux, J. E. (1996). *The Emotional Brain: The Mysterious Underpinnings of Emotional Life*. New York: Simon & Schuster. Retrieved from <https://books.google.co.nz/books?id=06ruAAAAMAAJ>
* Neal, M. (2013). Emotionally intelligent machines are closer than ever. Retrieved August 2, 2015, from <http://motherboard.vice.com/blog/emotionally-intelligent-machines-are-closer-than-ever>
* Pessoa, L. (2008). On the relationship between emotion and cognition. *Nature Reviews Neuroscience*, *9*(2), 148–158. <http://doi.org/10.1038/nrn2317>
* Russell, J. A. (2003). Core Affect and the Psychological Construction of Emotion. *Psychological Review*, *110*(1), 145–172. <http://doi.org/10.1037/0033-295X.110.1.145>
* Singh, S. K., Jha, S. S., & Nair, S. B. (2015). On Realizing Emotional Memories. In J. Vallverdú (Ed.), *Handbook of Research on Synthesizing Human Emotion in Intelligent Systems and Robotics:* IGI Global. Retrieved from 10.4018/978–1–4666–7278–9.ch005
* Swanson, L. W. (2005). Anatomy of the soul as reflected in the cerebral hemispheres: Neural circuits underlying voluntary control of basic motivated behaviours. *The Journal of Comparative Neurology*, *493*(1), 122–131. <http://doi.org/10.1002/cne.20733>
* Turkle, S. (2011). *Alone Together: Why We Expect More from Technology and Less from Each Other*. New York: Basic Books. Retrieved from <http://AUT.eblib.com.au/patron/FullRecord.aspx?p=684281>
* Zhang, Q., & Lee, M. (2009). Analysis of positive and negative emotions in natural scenes using brain activity and GIST. *Neurocomputing*, *72*(4), 1302–1306. <http://doi.org/10.1016/j.neucom.2008.11.007>

By [Clyde D'Souza](https://medium.com/@clydedz) on [January 25, 2025](https://medium.com/p/65198981baa).

[Canonical link](https://medium.com/@clydedz/should-computers-be-given-emotional-intelligence-65198981baa)

Exported from [Medium](https://medium.com) on August 22, 2025.
